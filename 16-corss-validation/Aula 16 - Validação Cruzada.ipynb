{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 16 - Validação Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting e Underfitting\n",
    "\n",
    "Capacidade e generalização são as duas qualidades que gostaríamos que nossos modelos de AM adquirissem: a primeira lhe da força para aprender as regularidades nos dados em que treinamos o modelo; a segunda faz com que ele consiga generalizar o que aprendeu para dados novos. Infelizmente essas duas forças então em polos opostos, de forma que ter mais de uma geralmente significa perder mais da outra. A seguir, vamos detalhar bem como esse tradeoff acontece e como ponderar essas duas forças. \n",
    "\n",
    "[Mais Sobre Capacidasde e Generalização...](https://matheusfacure.github.io/AM-Essencial/#Capacidade-e-generaliza%C3%A7%C3%A3o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para começar, vamos tentar prever quantos exercícios de estatística um estudante dadas as horas de estudos.\n",
    "De antemão, como vocês acham que é essa relação?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_parquet(\"/Users/matheus.facure/Downloads/produtividade.parquet\")\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = dataset.sample(15, random_state=42)\n",
    "\n",
    "samples.plot.scatter(x=\"horas\", y=\"exercicios\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em primeiro lugar, vamos ajustar uma reta aos nossos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LinearRegression()\n",
    "model1.fit(samples[[\"horas\"]], samples[\"exercicios\"])\n",
    "\n",
    "predictions = (samples\n",
    "               .assign(predictions = lambda df: model1.predict(df[[\"horas\"]])))\n",
    "               \n",
    "predictions.plot.scatter(x=\"horas\", y=\"exercicios\")\n",
    "plt.plot(predictions[\"horas\"], predictions[\"predictions\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(predictions[\"exercicios\"], predictions[\"predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Polinomial\n",
    "\n",
    "Em primeiro lugar, é preciso lembrar que, teoricamente, podemos aproximar qualquer função com um polinômio. Então, nós vamos utilizar esse fato para estender regressão linear para regressão polinomial. A ideia é bastante simples: a partir das variáveis existentes, **nós vamos construindo novas variáveis polinomiais e a regressão com elas terá mais capacidade quanto maior o grau do polinômio criado**.\n",
    "\n",
    "[Mais Sobre Regressão Polinomial...](https://matheusfacure.github.io/2017/02/26/regr-poli/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponents = range(1, 16)\n",
    "exp_col_names = [f\"horas_{exp}\" for exp in exponents]\n",
    "exp_hours = [samples[\"horas\"] ** exp for exp in exponents]\n",
    "\n",
    "samples_exp = (samples\n",
    "               .assign(**dict(zip(exp_col_names, exp_hours)))\n",
    "               .drop(columns=[\"horas\"]))\n",
    "\n",
    "# isso é uma forma mais programática de fazer\n",
    "# samples_exp = (samples\n",
    "#                .assign(horas_2 = dataset[\"horas\"] ** 2)\n",
    "#                .assign(horas_3 = dataset[\"horas\"] ** 3)\n",
    "#                .assign(horas_4 = dataset[\"horas\"] ** 4)\n",
    "#                ...\n",
    "#                .assign(horas_6 = dataset[\"horas\"] ** 6))\n",
    "\n",
    "samples_exp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com as features polinomiais prontas, podemos ajustar nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2 = LinearRegression()\n",
    "model2.fit(samples_exp[exp_col_names], samples_exp[\"exercicios\"])\n",
    "\n",
    "pred = (samples_exp\n",
    "        .assign(predictions = lambda df: model2.predict(df[exp_col_names]))\n",
    "        .sort_values(\"horas_1\")) # só pra deixar o plot mais bonitinho\n",
    "               \n",
    "pred.plot.scatter(x=\"horas_1\", y=\"exercicios\")\n",
    "plt.plot(pred[[\"horas_1\"]], pred[\"predictions\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(pred[\"exercicios\"], pred[\"predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qual dos Dois Modelos Acima é Melhor????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularização e Complexidade de Modelo\n",
    "\n",
    "### Capacidade e Generalização\n",
    "Vamos ver como nossos dois modeos se saem numa nova amostra de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_samples = dataset.sample(20, random_state=42)\n",
    "exponents = range(1, 16)\n",
    "exp_hours = [new_samples[\"horas\"] ** exp for exp in exponents]\n",
    "\n",
    "new_pred2 = (new_samples\n",
    "            .assign(**dict(zip(exp_col_names, exp_hours)))\n",
    "            .assign(predictions = lambda df: model2.predict(df[exp_col_names]))\n",
    "            .sort_values(\"horas_1\")\n",
    "            .drop(columns=[\"horas\"]))\n",
    "\n",
    "print(r2_score(new_pred2[\"exercicios\"], new_pred2[\"predictions\"]))\n",
    "\n",
    "new_pred2.plot.scatter(x=\"horas_1\", y=\"exercicios\")\n",
    "plt.plot(new_pred2[[\"horas_1\"]], new_pred2[\"predictions\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred1 = (new_samples\n",
    "            .assign(predictions = lambda df: model1.predict(df[[\"horas\"]])))\n",
    "\n",
    "print(r2_score(new_pred1[\"exercicios\"], new_pred1[\"predictions\"]))\n",
    "\n",
    "new_pred1.plot.scatter(x=\"horas\", y=\"exercicios\")\n",
    "plt.plot(new_pred1[[\"horas\"]], new_pred1[\"predictions\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E agora? Qual dos dois modelos é o melhor?\n",
    "\n",
    "\n",
    "### Regularização por Quantidade de Dados\n",
    "A forma mais fácil de regularizar os seus modelos é adicionando mais dados no set de treino. Assim, ele terá que usar toda a sua capacidade para ajustar apenas o sinal e deixar de lado o ruído.\n",
    "Para ver isso, retreine o modelo polinomial acima mas usando todos os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularização Algorítmica\n",
    "\n",
    "Mas nem sempre você terá dados suficientes para regularizar seu modelo. Por isso, todos os algorítmos de aprendizado de máquina tem um (ou vários) hiperparâmetro que controla a sua complexidade/capacidade. \n",
    "\n",
    "#### Regressão de  Ridge\n",
    "\n",
    "Diz a lenda que, para lidar com esse problema, alguns cientistas adicionavam um pequeno valor à diagonal de \\\\((X^T X)\\\\), tornando sua inversão mais estável. Ao fazer isso perceberam que a performance do modelo no set de avaliação melhorava. Com o tempo, o teoria estatística se desenvolveu para explicar essa melhora e é isso que veremos aqui. A primeira coisa que precisamos reparar é que \\\\((X^T X)\\\\) é uma matriz de covariância, ou seja, ela contém a informação de como cada variável de \\\\(X\\\\) correlaciona entre si. A diagonal de \\\\((X^T X)\\\\) tem o resultado das covariâncias das variáveis com elas mesmas, ou seja, as variâncias das variáveis de \\\\(X\\\\). Assim, adicionar um pequeno valor a diagonal de \\\\((X^T X)\\\\) é como aumentar artificialmente a variância nos dados. Isso torna o modelo mais robusto, melhorando sua generalização.\n",
    "\n",
    "Mais ainda, adicionar um pequeno valor \\\\(\\gamma^2\\\\) à diagonal de \\\\((X^T X)\\\\) é equivalente à adicionar um termo na nossa função custo, que passa de \\\\( (\\pmb{y} - \\pmb{\\hat{w}}X)^T(\\pmb{y} - \\pmb{\\hat{w}} X)\\\\) para\n",
    "\n",
    "$$\\mathcal{L} = (\\pmb{y} - \\pmb{\\hat{w}}X)^T(\\pmb{y} - \\pmb{\\hat{w}} X) + \\gamma \\pmb{\\hat{w}}^T \\pmb{\\hat{w}}$$\n",
    "\n",
    "Minimziar o primeiro termo da função objetivo acima corresponde a diminuir o erro no set de treino, ao passo que a minimização do segundo termo penaliza a complexidade do modelo. Com esse novo objetivo, o ponto ótimo passa a ser\n",
    "\n",
    "$$\\pmb{\\hat{w}} = (X^T X + \\gamma^2 I)^{-1} X^T \\pmb{y}$$\n",
    "\n",
    "\\\\(\\pmb{\\hat{w}}^T \\pmb{\\hat{w}}\\\\) também é chamado de norma L2 de \\\\(\\pmb{\\hat{w}}\\\\), cuja notação é \\\\(\\parallel\\pmb{\\hat{w}}\\parallel ^2\\\\). Do ponto de vista da otimização, isso adiciona uma segunda força, puxando o parâmetros \\(w\\) em direção a zero. Quanto maior for o \\\\(\\gamma\\\\), maior será essa força e maior será a regularização do modelo. O efeito disso é uma suavização da função aprendida pelo modelo. Por outro lado, é sempre bom lembrar que se \\\\(\\gamma\\\\) for muito grande, a regularização faz com que o modelo perca muita capacidade, sofrendo assim com muito viés.\n",
    "\n",
    "<img src=\"https://matheusfacure.github.io/img/tutorial/regularization/regularization_opt.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "[Mais Sobre Regressão de Ridge...](https://matheusfacure.github.io/2017/03/01/l2-reg/)\n",
    "\n",
    "#### Lasso\n",
    "\n",
    "Uma outra forma de regularizar é com a norma L1. Nesse caso, penalizamos o valor absoluto dos parâmetros.\n",
    "\n",
    "$$\\mathcal{L} = (\\pmb{y} - \\pmb{\\hat{w}}X)^T(\\pmb{y} - \\pmb{\\hat{w}} X) + \\gamma \\parallel\\pmb{\\hat{w}}\\parallel^1$$\n",
    "\n",
    "Isso força nosso problema de otimização para zero em várias das diminções. Em termos práticos, Lasso é uma boa para fazer seleção de variáveis mas costuma ser uma regularização muito forte. No geral, Rigde funciona melhor.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*Jd03Hyt2bpEv1r7UijLlpg.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "#### Elastic Net\n",
    "\n",
    "Finalmente temos Elastic-Net que é simplesmente uma combinação das duas regularizações acima.\n",
    "\n",
    "[Mais sobre elastic net](https://scikit-learn.org/stable/modules/linear_model.html#elastic-net)\n",
    "\n",
    "Indo na documetação do Sklear, você consegue ajustar algum desses modelos aos dados com variáveis polinomiais de forma a deixá-lo menos complexo? \n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import ...\n",
    "\n",
    "# model = ...\n",
    "# model.fit(samples_exp[exp_col_names], samples_exp[\"exercicios\"])\n",
    "\n",
    "# pred = (samples_exp\n",
    "#         .assign(predictions = lambda df: model.predict(df[exp_col_names]))\n",
    "#         .sort_values(\"horas_1\"))\n",
    "               \n",
    "# pred.plot.scatter(x=\"horas_1\", y=\"exercicios\")\n",
    "# plt.plot(pred[[\"horas_1\"]], pred[\"predictions\"])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dilema De Vies e Variancia\n",
    "\n",
    "Nós podemos tratar \\\\(\\hat{\\beta}\\\\) como uma variável aleatória. Pense nela como vários parâmetros que seriam aprendidos se utilizássemos apenas uma sub-amostra dos nossos dados para treinar vários modelos. Podemos então definir viés como a diferença entre a esperança dessa variável aleatória e os verdadeiros parâmetros do processo gerador dos dados: \\\\(E[\\hat{\\beta}] - \\beta\\\\). Quando essa diferença é zero, temos um estimador ŵ  que é não enviesado, algo que realmente gostaríamos que nossos modelos aprendessem. É importante lembrar que o viés mede a diferença esperada entre a função estimada e o verdadeiro processo gerador de dados.\n",
    "\n",
    "Além do viés, também precisamos considerar como as nossas estimativas variam com diferentes amostras. Isso pode ser medido pela variância: \\\\(Var(\\hat{\\beta})\\\\). Nós gostaríamos que a variância também fosse baixa, pois não queremos que o tipo de previsão do nosso modelo dependa bruscamente da amostra de dados em que ele foi treinado. Quando um modelo tem muita variância, a qualidade das nossas previsões dependerá muito da amostra que escolhermos para prever.\n",
    "\n",
    "Matematicamente, podemos mostrar que viés e variância são duas fontes de erro. Mais especificamente, a média do erro quadrado pode ser decomposta em viés e variância:\n",
    "\n",
    "$$\\pmb{MSE= Vies(\\hat{w})^2 + Var(\\hat{w})}$$\n",
    "\n",
    "![img](https://matheusfacure.github.io/img/screenshot-from-2017-02-11-17-11-55.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corss Validation\n",
    "\n",
    "Para achar o melhor ponto na curva acima, nós trenamos nosso modelo numa amostra e validamos ele em outra. Isso chama validação cruzada. Vamos voltar aos nossos dados da aula passada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data = (pd.read_parquet(\"/Users/matheus.facure/Downloads/bike_data.parquet\")\n",
    "             .dropna()\n",
    "             .sort_values([\"city\", \"dteday\"]))\n",
    "\n",
    "print(bike_data.shape)\n",
    "bike_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "Vamos criar variáveis que são exatamente iguais a cnt, só que no período anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = range(1, 14)\n",
    "\n",
    "dataset = (bike_data\n",
    "           .assign(**{f\"cnt_l{l}\": bike_data.groupby(\"city\")[\"cnt\"].shift(l) for l in lags}))\n",
    "           \n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E vamos adicionar variáveis dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores Faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variáveis e Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_features = [\"city\", \"dteday\", \"target\"]\n",
    "\n",
    "# similar to \n",
    "# features = list(filter(lambda col: col not in non_features, dataset.columns))\n",
    "features = [col for col in dataset.columns if col not in non_features]\n",
    "target = \"target\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "Em ML, um modelo raramente é apenas o algorítmo de aprendizado de máquina e envolve também passos de pré-processamento dos dados. Esses passo também precisam ser estimados nos dados de treino e aplicados nos dados de teste ou validação. Alguns exemplos são\n",
    "\n",
    "* Normalização das Features\n",
    "* Criar variáveis dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset[features], dataset[target],\n",
    "                                                    test_size=0.5, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(), # para treinar mais rápido\n",
    "                      Ridge())\n",
    "\n",
    "# treinamos em um dataset\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# validamos em outro dataset\n",
    "print(\"Train result:\", model.score(X_train, y_train)),\n",
    "print(\"Test result:\", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation\n",
    "\n",
    "Em vez de fazer validação cruzada uma única vez, podemos repetir o processo para vários sub-samples. Isso nos dará uma estimativa da variância do nosso modelo.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, dataset[features], dataset[target], cv=10)    \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_column = \"dteday\"\n",
    "dataset[time_column].min(), dataset[time_column].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_date = \"2011-01-01\"\n",
    "train_end_date = \"2012-03-01\"\n",
    "holdout_start_date = \"2012-05-01\"\n",
    "holdout_end_date = \"2012-12-21\"\n",
    "\n",
    "\n",
    "train_set = dataset[\n",
    "    (dataset[time_column] >= train_start_date) & (dataset[time_column] < train_end_date)]\n",
    "\n",
    "test_set = dataset[\n",
    "        (dataset[time_column] >= holdout_start_date) & (dataset[time_column] < holdout_end_date)]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_set[features], test_set[features], train_set[target], test_set[target]\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      Ridge(1e5))\n",
    "\n",
    "# treinamos em um dataset\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# validamos em outro dataset\n",
    "print(\"Train result:\", model.score(X_train, y_train)),\n",
    "print(\"Test result:\", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você consegue chegar em uma performance melhor? Acima de 0.25?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validação no Tempo e Espaço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_column=\"city\"\n",
    "\n",
    "train_period = dataset[\n",
    "        (dataset[time_column] >= train_start_date) & (dataset[time_column] < train_end_date)]\n",
    "\n",
    "outime_holdout = dataset[\n",
    "        (dataset[time_column] >= train_end_date) & (dataset[time_column] < holdout_end_date)]\n",
    "\n",
    "train_period_space = np.sort(train_period[space_column].unique())\n",
    "\n",
    "holdout_space = np.random.choice(train_period_space,\n",
    "                                 int(0.3 * len(train_period_space)), replace=False)\n",
    "\n",
    "train_set = train_period[~train_period[space_column].isin(holdout_space)]\n",
    "intime_outspace_hdout = train_period[train_period[space_column].isin(holdout_space)]\n",
    "outime_outspace_hdout = outime_holdout[outime_holdout[space_column].isin(holdout_space)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_set[features], outime_outspace_hdout[features], train_set[target], outime_outspace_hdout[target]\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      Ridge(1e0))\n",
    "\n",
    "# treinamos em um dataset\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# validamos em outro dataset\n",
    "print(\"Train result:\", model.score(X_train, y_train)),\n",
    "print(\"Test result:\", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
