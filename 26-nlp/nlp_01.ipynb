{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "![](data/imgs/nlp_intro.png)\n",
    "\n",
    "*pegar referência\n",
    "\n",
    "## O que vem na cabeça de vocês quando falamos de Processamento de Linguagem Natural?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição\n",
    "\n",
    "O termo NLP (Natural Laguage Processing, ou Processamento de Linguagem Natural em tradução livre) é um campo da computação relativamente novo e que tem como principal foco fazer com que as máquinas entendam e até possam se comunicar em linguagem humana. É uma área de pesquisa/atuação extremamente ampla, podendo se dividir em ramos com atuações muito diferentes. Alguns dos principais exemplos de atuação são:\n",
    "\n",
    "- Information Retrieval: Com base em uma query do usuário, retornar o produto/documento que atenda suas expectativas (**Google**)\n",
    "- Q&A: Com base em uma pergunta, encontrar a resposta que mais atenda ela (**Watson/Jeopardy**)\n",
    "- Machine Translation: entrar uma linguagem em um idioma e traduzí-la (**Google Translate**)\n",
    "- Information Extraction: \n",
    "![](data/imgs/avril_height.png)\n",
    "- Sentiment Analysis: é o que veremos hoje !\n",
    "\n",
    "\n",
    "<img src=\"data/imgs/yeah_gif.gif\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextualizando\n",
    "\n",
    "Suponha que você seja um Cientista de Dados e trabalha em um app de um restaurante. Você conseguiu coletar os reviews de alguns dos seus clientes e pretende pensar como que você agrega valor com eles.**\n",
    "\n",
    "**ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Oh, and there's hookah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>I have to say that I am pleasantly suprised and I will most likely stop in again if I am in the neighborhood.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Not sure if I would go back.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>The pastas are incredible, the risottos (particularly the sepia) are fantastic and the braised rabbit is amazing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>If you're in the area you shouldn't be disappointed.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  text\n",
       "47                                                                                             Oh, and there's hookah.\n",
       "165      I have to say that I am pleasantly suprised and I will most likely stop in again if I am in the neighborhood.\n",
       "19                                                                                        Not sure if I would go back.\n",
       "76   The pastas are incredible, the risottos (particularly the sepia) are fantastic and the braised rabbit is amazing.\n",
       "308                                                               If you're in the area you shouldn't be disappointed."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = 999\n",
    "pd.read_csv('data/reviews/raw_reviews.csv').sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça um sample dos dados e explore um pouco eles. Entenda que tipo de informação você tem e o que você consegue fazer com ela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO\n",
    "\n",
    "#TENTE ENTENDER UM POUCO SEUS DADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tá mas e daí?\n",
    "\n",
    "Se vocês tentarem interpretar o conteúdo, vocês verão que os reviews retratam **opiniões**. Extrapolando um pouco, da pra ver que essas opiniões estão bem **polarizadas** ou em algo *positivo* ou em algo *negativo*. Ora, vocês reconhecem esse tipo de trabalho? E se anotássemos as labels em categorias (positiva ou negativa) e construíssimos um *classificador* para esses reviews?\n",
    "\n",
    "Ou seja, nosso modelo irá receber um **texto** como *feature* e irá retornar uma **classe**: positiva ou negativa. Ou seja, nosso modelo irá **analisar o sentimento** expresso por um certo texto !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It is nearly impossible to get a table, so if you ever have the chance to go here for dinner, DO NOT pass it up.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I won't go back unless someone else is footing the bill.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There are so many better places to visit!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This place is a must visit!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>but the service was a bit slow.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               text  \\\n",
       "0  It is nearly impossible to get a table, so if you ever have the chance to go here for dinner, DO NOT pass it up.   \n",
       "1                                                          I won't go back unless someone else is footing the bill.   \n",
       "2                                                                         There are so many better places to visit!   \n",
       "3                                                                                       This place is a must visit!   \n",
       "4                                                                                   but the service was a bit slow.   \n",
       "\n",
       "   polarity  \n",
       "0  positive  \n",
       "1  negative  \n",
       "2  negative  \n",
       "3  positive  \n",
       "4  positive  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/reviews/train.csv')\n",
    "test_df = pd.read_csv('data/reviews/test.csv')\n",
    "\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/imgs/wat-wat-wat.jpg\" align=\"center\"/>\n",
    "\n",
    "\n",
    "Calma que já vamos entender tudo !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As ferramentas\n",
    "\n",
    "A principal biblioteca existente hoje para trabalhos de NLP é o Spacy. O datacamp lançou recentemente um [curso](https://campus.datacamp.com/courses/advanced-nlp-with-spacy) bem legal sobre ele que vale a pena dar uma conferida já que hoje, focaremos no \"básico\".\n",
    "\n",
    "Outra lib que vale citar é o NLTK, principal biblioteca de NLP a alguns anos atrás.\n",
    "\n",
    "Com o advento de deep learning, outras inciativas também ficaram famosas, como o [AllenNLP](https://allennlp.org/) e o [StanfordNLP](https://stanfordnlp.github.io/stanfordnlp/), que são capazes de atingir o estado da arte de muitas aplicações !\n",
    "\n",
    "### O Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baixando o modelo de inglês\n",
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No centro do Spacy tem o conceito de objeto que contém todo o pipeline de processamento, além de outras regras específicas de uma certa língua. Essa variável é comummente chamada de *nlp*. Por exemplo, para criar um objeto *nlp* da língua inglesa, basta fazer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando você processa um texto com o objecto *nlp*, o *Spacy* cria um *Doc* object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"It's also attached to Angel's Share, which is a cool, more romantic bar...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O *doc* permite você acessar os dados dos seus textos de maneira estruturada. A forma de iteração é de uma sequência de pytho, então:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It\n",
      "'s\n",
      "also\n",
      "attached\n",
      "to\n",
      "Angel\n",
      "'s\n",
      "Share\n",
      ",\n",
      "which\n",
      "is\n",
      "a\n",
      "cool\n",
      ",\n",
      "more\n",
      "romantic\n",
      "bar\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data/imgs/spacy_01.png)\n",
    "\n",
    "\n",
    "Note que no Spacy, o objeto *Token* é um objeto que possui vários atributos. Alguns importantes/legais:\n",
    "\n",
    "![](data/imgs/spacy_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Um pouco de prática ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isso é uma sentença\n"
     ]
    }
   ],
   "source": [
    "# Import the Portuguese language class\n",
    "from spacy.lang.____ import ____\n",
    "\n",
    "# Create the nlp object\n",
    "nlp = ____\n",
    "\n",
    "# Process a text\n",
    "doc = nlp(\"Isso é uma sentença\")\n",
    "\n",
    "# Print the document text\n",
    "print(____.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Spanish language class and create the nlp object\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(\"Me gustan los canguros de los árboles y los narvales )\n",
    "\n",
    "# Select the first token\n",
    "first_token = doc[0]\n",
    "\n",
    "# Print the first token's text\n",
    "print(first_token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the text\n",
    "doc = nlp(\"In 1990, more than 60% of people in East Asia were in extreme poverty. Now less than 4% are.\")\n",
    "\n",
    "# Iterate over the tokens in the doc\n",
    "for token in doc:\n",
    "    # Check if the token resembles a number\n",
    "    if ____.____:\n",
    "        # Get the next token in the document. The index of the next token in the doc is token.i + 1.\n",
    "        next_token = ____[____]\n",
    "        # Check if the next token's text equals '%'\n",
    "        if next_token.____ == '%':\n",
    "            print('Percentage found:', token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Um pouco de estatística\n",
    "\n",
    "É possível carregar alguns modelos pré treinados no Spacy para nos atender em alguns pontos específicos. O caso mais popular é caso queiramos analisar se determinada palavra é um verbo, ou é um nome próprio (po ex: Apple companhia ou apple, a fruta).\n",
    "\n",
    "Esses modelos estatísticos permitem ao spacy prever atriutos linguísticos, principalmente:\n",
    "\n",
    "- Part-of-Speech tags (classificação gramátical)\n",
    "- Nomeação de Entidades (Ex: a Apple companhia, 'Play Photograph')\n",
    "- Words relationship (Dependecy parser)\n",
    "\n",
    "Tais modelos específicos estão divididos em pacotes e precisam ser baixados. O 'en_core_web_sm' é um pacote com vários modelos treinados em inglês."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON\n",
      "ate VERB\n",
      "the DET\n",
      "pizza NOUN\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(\"She ate the pizza\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photograph ORG\n",
      "Nicklelback PERSON\n",
      "yesterday DATE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I heard Photograph from Nicklelback yesterday !\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "#note Photograph is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I heard photograph from Nicklelback!\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I took the photograph!\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercicio\n",
    "\n",
    "Imprima as entidades da frase abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"New iPhone X release date leaked as Apple reveals pre-orders by mistake\"\n",
    "\n",
    "# Process the text\n",
    "doc = ____\n",
    "\n",
    "# Iterate over the entities\n",
    "for ____ in ____.____:\n",
    "    # print the entity text and label\n",
    "    print(____.____, ____.____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords\n",
    "\n",
    "Para muitas tarefas de NLP, é bom prestar atenção nas chamadas stopwords, que são as palavras mais comuns que aparecem no texto.\n",
    "\n",
    "Como assim? Vamos tokenizar (de maneira simplista, mas note que estamos usando expressões regulares. Para refrescar a memória, você pode usar o [regex golf](https://alf.nu/RegexGolf)) e imprimir as palavras mais comuns da coluna text de nosso dataset de treino.\n",
    "\n",
    "Poderíamos usar a ideia de Matcher (ensinada no curso do Datacamp), exclusiva do spacy, mas eu acredito que regex são uteis para varias situações !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 309),\n",
       " ('the', 177),\n",
       " ('a', 103),\n",
       " ('to', 97),\n",
       " ('and', 92),\n",
       " ('i', 90),\n",
       " ('is', 79),\n",
       " ('it', 75),\n",
       " ('for', 56),\n",
       " ('you', 55)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splita as frases por palavras (espaco incluido) e soma elas\n",
    "Counter(sum(train_df['text'].str.lower().str.split(r'[\\W\\s]+').tolist(), [])).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É meio intuitivo o que queremos dizer com *stopwords*, correto?\n",
    "\n",
    "No spacy, podemos encontrar as stopwords do nosso modelo assim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no', 'nobody', 'none', 'noone', 'nor', 'not']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_stopwords = sorted([token.text for token in nlp.vocab if token.is_stop])\n",
    "en_stopwords[155:161]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre-se que estamos avaliando a polaridade. Então na hora de analisarmos o texto, seria  horrível perder certas stopwords como palavras de negação, afinal, \"Eu não gosto disso\" é muito diferente de \"Eu gosto disso\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
