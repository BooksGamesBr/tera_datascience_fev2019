{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós vamos utilizar o dataset Bank Marketing disponibilizado no [site da UCI](http://archive.ics.uci.edu/ml/datasets/Bank+Marketing). Utilizaremos uma versão adaptada para os objetivos da aula e disponível na pasta `data`.\n",
    "\n",
    "> The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the investment product would be or not subscribed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from lightgbm import LGBMClassifier, plot_metric, plot_tree, create_tree_digraph\n",
    "from auto_lgbm import find_n_estimators, grid_search\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from evaluation import predictions_hist, confusion_matrix_report, grid_search_report\n",
    "\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.5)\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/bank_marketing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segue uma descrição sucinta de cada uma das colunas do dataset:\n",
    "\n",
    "- `duration_seconds`: last contact duration, in seconds (numeric).\n",
    "\n",
    "- `duration_minutes`: last contact duration, in minutes (numeric).\n",
    "\n",
    "- `duration_hours`: last contact duration, in hours (numeric).\n",
    "\n",
    "- `emp.var.rate`: employment variation rate - quarterly indicator (numeric)\n",
    "\n",
    "- `nr.employed`: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "- `euribor3m`: euribor 3 month rate - daily indicator (numeric)\n",
    "\n",
    "- `month`: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "\n",
    "- `contact`: contact communication type (1 for cellular, 2 for telephone) \n",
    "\n",
    "- `loan`: has personal loan? (0 for no, 1 for yes)\n",
    "\n",
    "- `subscribed` - has the client subscribed a term deposit? (True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['month', 'subscribed'])\n",
    "y = df['subscribed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando o Gradient Boosting (implementação da LightGBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize a classe `LGBMClassifier` para criar um modelo, treiná-lo e calcular as predições no dataset de teste.\n",
    "\n",
    "Salve o modelo na variável `lgbm` e as predições em uma variável chamada `y_pred_proba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = <code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize as predições com a função `predictions_hist`, que acompanha este notebook no módulo `evaluation`, e defina um ponto de corte para a matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = predictions_hist(y_pred_proba, y_test, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_report(y_test, y_pred_proba, thres=<code>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize a função `log_loss` para calcular o log loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização de árvores da LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós podemos ver acima que o nosso modelo foi treinado com `n_estimators=100` e `num_leaves=31`. Ou seja, o modelo compreende de 100 árvores de decisão, cada uma com até 31 folhas. Vamos plotar as 2 primeiras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_tree_digraph(lgbm, tree_index=0)\n",
    "_ = plot_tree(lgbm, tree_index=0, figsize=(150, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plote a segunda árvore de decisão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelando com features categóricas e early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize o atributo `dtypes` da classe `DataFrame` para identificar o tipo da coluna `month`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que a LightGBM trate a coluna `month` como uma feature categórica, é necessário que modiquemos seu tipo no Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['month'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos então adicionar a coluna `month` e refazer o split entre treino e teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = df.drop(columns=['subscribed'])\n",
    "\n",
    "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(X_cat, y, test_size=0.2, \n",
    "                                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o early stopping, vamos quebrar o dataset de treino, que representa 80% dos dados, entre `dev` e `val`, de forma de `dev` fique com 60% dos dados e `val` com 20%. Ou seja, utilize a função `train_test_split` para criar `X_dev`, `X_val`, `y_dev` e `y_val`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = <code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_es = LGBMClassifier(n_estimators=3000,\n",
    "                         class_weight='balanced', random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos invocar o método `fit` da nossa LightGBM, utilizando `X_dev` e `y_dev` para treino, além de setar `eval_set` e `early_stopping_rounds`, de forma que a LightGBM utilize o dataset de validação para parar a adição de árvores depois de 50 iterações sem melhoria na métrica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_es = lgbm_es.predict_proba(X_test_cat)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_test_cat, y_pred_proba_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunando o parâmetro `learning_rate` também"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defina a variável `learning_rate` de forma que seja uma lista contendo os valores `0.01`, `0.03` e `0.1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_estimators = 3000\n",
    "early_stopping_rounds = 50\n",
    "learning_rates = <code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_md = LGBMClassifier(n_estimators=max_n_estimators, \n",
    "                         class_weight='balanced', random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preencha o código abaixo, de forma que a cada iteração do loop, seja treinada uma LightGBM com early stopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['max_depth', 'best_n_estimators', 'best_log_loss'])\n",
    "\n",
    "for learning_rate in tqdm(learning_rates):\n",
    "    <code>\n",
    "    \n",
    "    results = results.append({'learning_rate': learning_rate, \n",
    "                              'best_n_estimators': lgbm_md.best_iteration_,\n",
    "                              'best_log_loss': lgbm_md.best_score_['valid_0']['binary_logloss']},\n",
    "                             ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na célula acima, é possível ver que a LightGBM salva o melhor valor encontrada para `n_estimators` no atributo `best_iteration_` e o seu desempenho em um dicionário que pode ser acessado pelo atributo `best_score_`.\n",
    "\n",
    "Vamos então exibir os resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['learning_rate'] = results['learning_rate'].astype(int)\n",
    "results['best_n_estimators'] = results['best_n_estimators'].astype(int)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No mais, note que, quanto menor o `learning_rate`, maior é o `n_estimators`. Por consequência, maior também serão os tempos de treino e de predição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search com os melhores conjuntos de parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos utilizar os melhores resultados obtidos na seção anterior e conferir via validação cruzada qual, de fato, é o melhor conjunto de hyper-parâmetros.\n",
    "\n",
    "Para isso, a próxima célula cria grids de parâmetros. Note que isso é muito mais eficiente do que se criar somente um grid com todos esses parâmetros, já que o número de conjuntos de parâmetros a serem treinados passaria a ser a combinação de todos os valores (8*8=`64` ao invés de somente `8`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = [\n",
    "    {'learning_rate': [0.01], 'n_estimators': [1768]},\n",
    "    {'learning_rate': [0.03], 'n_estimators': [785]},\n",
    "    {'learning_rate': [0.1], 'n_estimators': [302]}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No algoritmo de cross-validation do scikit-learn, quanto maior a métrica, melhor o modelo. Para poder-se utilizar esse tipo de algoritmo com métricas que tentam minimizar um erro (e.g., log loss), a métrica é negada, ou seja, multiplicada por `-1`.\n",
    "\n",
    "A [lista de métricas pré-definidas](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules) pode ser encontrada na documentação do scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'neg_log_loss'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, instancie a classe `GridSearchCV` com 3 folds de validação cruzada e o parâmetro `verbose=2`, além de passar outros parâmetros necessários:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv = <code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.fit(X_train_cat, y_train_cat, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `grid_search_report` foi criada por nós para facilitar a visualização dos resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_report(grid_search_cv.grid_scores_, scoring, scoring_alias='log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por coincidência, podemos ver que o melhor learning_rate encontrado é justamente o valor default. Ou seja, esse modelo é o mesmo da seção anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretando o modelo\n",
    "\n",
    "Para interpretar o modelo, utilizaremos o [SHAP](https://github.com/slundberg/shap).\n",
    "\n",
    "Para não despendermos muito tempo calculando os SHAP values, utilizaremos uma amostra aleatória de 100 exemplos. Além disso, vamos utilizar o dataset/modelo sem variáveis categóricas por simplicidade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample = X_train.sample(1_000, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `TreeExplainer`, ao contrário do `KernelExplainer` que é genérico, é otimizado para modelos baseados em árvores e tem suporte à LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(lgbm, data=X_train_sample)\n",
    "shap_values = explainer.shap_values(X_train_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os SHAP values são nada mais do que a contribuição de cada variável para cada predição. A sua unidade é sempre a mesma unidade do target.\n",
    "\n",
    "Com os SHAP values calculados, vamos plotar os feature importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train_sample, plot_type='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifique o parâmetro `plot_type='bar'` para `plot_type='dot'`. Veja que agora é possível fazer uma análise mais aprofundada com o summary plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos dar um deep dive em algumas features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pense no `dependence_plot` como um zoom que nós podemos dar para entender o que o modelo aprendeu com relação a uma feature específica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependence_plot(feature, show=True):\n",
    "    shap.dependence_plot(feature, shap_values, X_train_sample, \n",
    "                         interaction_index=feature, show=show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show=False e o xlim na linha de baixo é para não exibirmos outliers\n",
    "dependence_plot('duration_seconds', show=False)\n",
    "_ = plt.xlim(0, 1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependence_plot('emp.var.rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nome `dependence plot` é dado ao fato de que o SHAP automaticamente identifica qual é a variável que mais interage com a variável em questão e exibe o seu comportamento dependendo dessa outra variável.\n",
    "\n",
    "O parâmetro `interaction_index` nos permite selecionar qualquer outra variável para essa comparação. Setanto esse parâmetro para a própria feature, deixamos de ver interação dela com outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'euribor3m'\n",
    "shap.dependence_plot(feature, shap_values, X_train_sample, \n",
    "                     interaction_index=feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'nr.employed'\n",
    "shap.dependence_plot(feature, shap_values, X_train_sample, \n",
    "                     interaction_index=feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: vamos analisar algumas predições"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembram da função logística (a.k.a., sigmoid)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return math.exp(x) / (math.exp(x) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.expected_value, logistic(explainer.expected_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A célula de cima nos diz que o valor esperado (ou seja a média) das predições no dataset de teste é ~2.4%.\n",
    "\n",
    "O `force_plot` é uma analogia à física. As variáveis em vermelho \"empurram\" o valor da predição para ser mais alto, quanto as variáveis em azul \"empurram\" o valor da predição para baixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_plot(id_):\n",
    "    return shap.force_plot(explainer.expected_value, shap_values[id_, :], \n",
    "                           X_train_sample.iloc[id_, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma ótima avaliação de um classificador pode ser analisar os force plots dos falsos positivos scores mais altos e os falsos negativos com scores mais baixos. Essa estratégia tem o potencial de 1) ajudar a identificar features relevantes que não estão no modelo; e/ou 2) fazer com que stakeholders ganhem confiança no modelo caso os erros façam sentido.\n",
    "\n",
    "Vamos aplicar o `force_plot` à primeira observação da amostra aleatória:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_plot(id_=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar a interpretação do valor predito, basta aplicar a função logística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic(-8.84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_plot(id_=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic(1.6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
